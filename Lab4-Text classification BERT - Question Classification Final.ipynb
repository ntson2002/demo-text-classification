{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4bccfd5-018c-41db-b6b1-ef411479b4e9",
   "metadata": {},
   "source": [
    "# Convert TREC data to JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0605ca8c-62d3-4ca7-8745-ad1fbb23bac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import codecs\n",
    "def _generate_examples(filepath):\n",
    "    label2id = {'ABBR':0, 'DESC':1, 'ENTY':2, 'HUM':3, 'LOC':4, 'NUM':5}\n",
    "    id2label = {0:'ABBR', 1:'DESC', 2:'ENTY', 3:'HUM', 4:'LOC', 5:'NUM'}\n",
    "    examples = []\n",
    "    with codecs.open(filepath, \"rb\") as f:\n",
    "        for id_, row in enumerate(f):\n",
    "            # One non-ASCII byte: sisterBADBYTEcity. We replace it with a space\n",
    "            label, _, text = row.replace(b\"\\xf0\",\n",
    "                                         b\" \").strip().decode().partition(\" \")\n",
    "            coarse_label, _, fine_label = label.partition(\":\")\n",
    "            examples.append({\n",
    "                'id': id_, \n",
    "                # \"label-fine\": fine_label,\n",
    "                \"text\": text,\n",
    "                \"label\": label2id[coarse_label],\n",
    "                \"label-coarse\": coarse_label,                \n",
    "            })\n",
    "    return examples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b9a50c8-a10d-4fe6-9b18-bc6820c891b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = _generate_examples(\"train_5500.label\")\n",
    "test = _generate_examples(\"TREC_10.label\")\n",
    "from kiki_utils.common.helpers import *\n",
    "write_json(train, \"trec_train.json\")\n",
    "write_json(test, \"trec_test.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0c5c9d2-029b-4546-9ef3-eb715e4fc35d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 5452 Test: 500\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train: {len(train)} Test: {len(test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7c2cd953-b198-4978-8e1e-2249d4d97d93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# IMPORTS\n",
    "# =============================================================================\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import warnings\n",
    "from datasets import Dataset\n",
    "import evaluate\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorWithPadding\n",
    ")\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# CONFIGURATION\n",
    "# =============================================================================\n",
    "# Environment variables - Set BEFORE any imports that use them\n",
    "os.environ['HTTP_PROXY'] = \"http://10.60.28.99:81\"\n",
    "os.environ['HTTPS_PROXY'] = \"http://10.60.28.99:81\"\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'false'  # Fix tokenizers parallelism warning\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'  # Optional: disable oneDNN if not needed\n",
    "\n",
    "# Model configuration\n",
    "MODEL_NAME = \"distilbert-base-uncased\"\n",
    "OUTPUT_DIR = \"trec_model\"\n",
    "NUM_LABELS = 6  # Updated to 6 labels\n",
    "\n",
    "# Updated label mappings for 6 classes\n",
    "id2label = {0: 'ABBR', 1: 'DESC', 2: 'ENTY', 3: 'HUM', 4: 'LOC', 5: 'NUM'}\n",
    "label2id = {'ABBR': 0, 'DESC': 1, 'ENTY': 2, 'HUM': 3, 'LOC': 4, 'NUM': 5}\n",
    "\n",
    "# Training hyperparameters\n",
    "LEARNING_RATE = 2e-5\n",
    "BATCH_SIZE = 16\n",
    "NUM_EPOCHS = 4\n",
    "WEIGHT_DECAY = 0.01\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# DATA LOADING FUNCTIONS\n",
    "# =============================================================================\n",
    "def load_from_json(filename):\n",
    "    \"\"\"Load dataset from a JSON file and convert to Hugging Face Dataset format\"\"\"\n",
    "    with open(filename, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    # Extract texts and labels\n",
    "    texts = [item['text'] for item in data]\n",
    "    labels = [item['label'] for item in data]\n",
    "    \n",
    "    # Convert to Hugging Face Dataset\n",
    "    dataset = Dataset.from_dict({\n",
    "        'text': texts,\n",
    "        'label': labels\n",
    "    })\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# PREPROCESSING FUNCTIONS\n",
    "# =============================================================================\n",
    "# Note: These functions need to be defined at module level for proper serialization\n",
    "def create_preprocess_function(tokenizer):\n",
    "    \"\"\"Create a preprocessing function with tokenizer\"\"\"\n",
    "    def preprocess_function(examples):\n",
    "        \"\"\"Tokenize text examples\"\"\"\n",
    "        return tokenizer(examples[\"text\"], truncation=True, padding=False)\n",
    "    return preprocess_function\n",
    "\n",
    "\n",
    "def create_compute_metrics(accuracy_metric):\n",
    "    \"\"\"Create a compute metrics function with accuracy metric\"\"\"\n",
    "    def compute_metrics(eval_pred):\n",
    "        \"\"\"Compute accuracy metrics for evaluation\"\"\"\n",
    "        predictions, labels = eval_pred\n",
    "        predictions = np.argmax(predictions, axis=1)\n",
    "        return accuracy_metric.compute(predictions=predictions, references=labels)\n",
    "    return compute_metrics\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf2d494-fde0-4682-b301-8d85f4c1a61d",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "48b48dc5-c51e-49e9-993d-98fa9996a198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading from JSON files...\n",
      "Train dataset size: 5452\n",
      "Test dataset size: 500\n",
      "\n",
      "Initializing tokenizer...\n",
      "Tokenizing datasets...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb037633e7364de199526848d127937f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing training data:   0%|          | 0/5452 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4de74608bfb84f7cb330a17b61da04f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing test data:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Initializing data collator and metrics...\n",
      "\n",
      "Initializing model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Initializing trainer...\n",
      "\n",
      "Starting training...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1364' max='1364' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1364/1364 01:26, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.201156</td>\n",
       "      <td>0.948000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.504300</td>\n",
       "      <td>0.145282</td>\n",
       "      <td>0.968000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.110500</td>\n",
       "      <td>0.156016</td>\n",
       "      <td>0.970000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.110500</td>\n",
       "      <td>0.151031</td>\n",
       "      <td>0.970000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving model...\n",
      "\n",
      "Evaluating on test set...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [32/32 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test results: {'eval_loss': 0.14528198540210724, 'eval_accuracy': 0.968, 'eval_runtime': 0.2597, 'eval_samples_per_second': 1925.316, 'eval_steps_per_second': 123.22, 'epoch': 4.0}\n",
      "\n",
      "Training completed successfully!\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# MAIN EXECUTION\n",
    "# =============================================================================\n",
    "if __name__ == \"__main__\":\n",
    "    \"\"\"Main training function\"\"\"\n",
    "    # Load datasets\n",
    "    print(\"\\nLoading from JSON files...\")\n",
    "    train_dataset = load_from_json('trec_train.json')\n",
    "    test_dataset = load_from_json('trec_test.json')\n",
    "    print(f\"Train dataset size: {len(train_dataset)}\")\n",
    "    print(f\"Test dataset size: {len(test_dataset)}\")\n",
    "    \n",
    "    # Initialize tokenizer\n",
    "    print(\"\\nInitializing tokenizer...\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "    \n",
    "    # Create preprocessing function\n",
    "    preprocess_function = create_preprocess_function(tokenizer)\n",
    "    \n",
    "    # Tokenize datasets\n",
    "    print(\"Tokenizing datasets...\")\n",
    "    tokenized_train_imdb = train_dataset.map(\n",
    "        preprocess_function, \n",
    "        batched=True,\n",
    "        desc=\"Tokenizing training data\"\n",
    "    )\n",
    "    tokenized_test_imdb = test_dataset.map(\n",
    "        preprocess_function, \n",
    "        batched=True,\n",
    "        desc=\"Tokenizing test data\"\n",
    "    )\n",
    "    \n",
    "    # Initialize data collator and metrics\n",
    "    print(\"\\nInitializing data collator and metrics...\")\n",
    "    data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "    accuracy = evaluate.load(\"accuracy\")\n",
    "    compute_metrics = create_compute_metrics(accuracy)\n",
    "    \n",
    "    # Initialize model\n",
    "    print(\"\\nInitializing model...\")\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        MODEL_NAME,\n",
    "        num_labels=NUM_LABELS,  # Updated for 6 labels\n",
    "        id2label=id2label,\n",
    "        label2id=label2id\n",
    "    )\n",
    "    \n",
    "    # Configure training arguments\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=OUTPUT_DIR,\n",
    "        learning_rate=LEARNING_RATE,\n",
    "        per_device_train_batch_size=BATCH_SIZE,\n",
    "        per_device_eval_batch_size=BATCH_SIZE,\n",
    "        num_train_epochs=NUM_EPOCHS,\n",
    "        weight_decay=WEIGHT_DECAY,\n",
    "        eval_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        load_best_model_at_end=True,\n",
    "        push_to_hub=False,\n",
    "        report_to=\"none\",  # Disable all reporting including wandb\n",
    "        logging_steps=500,\n",
    "        logging_dir=f\"{OUTPUT_DIR}/logs\",\n",
    "        dataloader_num_workers=0,  # Avoid multiprocessing issues\n",
    "    )\n",
    "    \n",
    "    # Initialize trainer - use processing_class instead of tokenizer\n",
    "    print(\"\\nInitializing trainer...\")\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=tokenized_train_imdb,\n",
    "        eval_dataset=tokenized_test_imdb,\n",
    "        processing_class=tokenizer,  # Use processing_class instead of tokenizer\n",
    "        data_collator=data_collator,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "    \n",
    "    # Start training\n",
    "    print(\"\\nStarting training...\")\n",
    "    train_result = trainer.train()\n",
    "    \n",
    "    # Save the final model\n",
    "    print(\"\\nSaving model...\")\n",
    "    trainer.save_model()\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    print(\"\\nEvaluating on test set...\")\n",
    "    test_results = trainer.evaluate(tokenized_test_imdb)\n",
    "    print(f\"Test results: {test_results}\")\n",
    "    \n",
    "    print(\"\\nTraining completed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e0a088e4-34de-4d44-bdee-deaabe58efb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.14528198540210724,\n",
       " 'eval_accuracy': 0.968,\n",
       " 'eval_runtime': 0.2597,\n",
       " 'eval_samples_per_second': 1925.316,\n",
       " 'eval_steps_per_second': 123.22,\n",
       " 'epoch': 4.0}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1cdc6893-4e48-41fc-8782-c3e767a7d90e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint-1023  checkpoint-682     special_tokens_map.json  training_args.bin\n",
      "checkpoint-1364  config.json\t    tokenizer_config.json    vocab.txt\n",
      "checkpoint-341\t model.safetensors  tokenizer.json\n"
     ]
    }
   ],
   "source": [
    "! ls trec_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5c157d-9335-4848-8bfa-240e3745b204",
   "metadata": {},
   "source": [
    "# Load and inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9902983a-f12f-4edb-96be-bf00b31ce78b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading from trec_test.json...\n",
      "Test dataset size: 500\n",
      "\n",
      "Initializing tokenizer...\n",
      "Tokenizing test data...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9cdd2697d0d4410b3f0a1d38c61d6a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing test data:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading model from checkpoint...\n",
      "\n",
      "Performing inference on the test dataset...\n",
      "Accuracy: 97.00%\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# IMPORTS\n",
    "# =============================================================================\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from sklearn.metrics import accuracy_score  # For manual accuracy calculation\n",
    "\n",
    "# =============================================================================\n",
    "# CONFIGURATION\n",
    "# =============================================================================\n",
    "# Environment variables - Set BEFORE any imports that use them\n",
    "os.environ['HTTP_PROXY'] = \"http://10.60.28.99:81\"\n",
    "os.environ['HTTPS_PROXY'] = \"http://10.60.28.99:81\"\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'false'  # Fix tokenizers parallelism warning\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'  # Optional: disable oneDNN if not needed\n",
    "\n",
    "# Model configuration\n",
    "MODEL_NAME = \"distilbert-base-uncased\"\n",
    "OUTPUT_DIR = \"trec_model\"\n",
    "CHECKPOINT_PATH = os.path.join(OUTPUT_DIR, \"checkpoint-1364\")  # Path to the checkpoint\n",
    "NUM_LABELS = 6  # Number of classes\n",
    "\n",
    "# Updated label mappings for 6 classes\n",
    "id2label = {0: 'ABBR', 1: 'DESC', 2: 'ENTY', 3: 'HUM', 4: 'LOC', 5: 'NUM'}\n",
    "label2id = {'ABBR': 0, 'DESC': 1, 'ENTY': 2, 'HUM': 3, 'LOC': 4, 'NUM': 5}\n",
    "\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# MAIN EXECUTION\n",
    "# =============================================================================\n",
    "if __name__ == \"__main__\":\n",
    "    \"\"\"Load the model, perform inference and calculate accuracy\"\"\"\n",
    "    # Load the test dataset (trec_test.json)\n",
    "    print(\"\\nLoading from trec_test.json...\")\n",
    "    test_dataset = load_from_json('trec_test.json')\n",
    "    print(f\"Test dataset size: {len(test_dataset)}\")\n",
    "    \n",
    "    # Initialize tokenizer\n",
    "    print(\"\\nInitializing tokenizer...\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "    \n",
    "    # Tokenize the test dataset\n",
    "    print(\"Tokenizing test data...\")\n",
    "    def preprocess_function(examples):\n",
    "        \"\"\"Tokenize text examples\"\"\"\n",
    "        return tokenizer(examples[\"text\"], truncation=True, padding=True, max_length=128)\n",
    "    \n",
    "    tokenized_test_data = test_dataset.map(\n",
    "        preprocess_function, \n",
    "        batched=True,\n",
    "        desc=\"Tokenizing test data\"\n",
    "    )\n",
    "\n",
    "    # Load the model from checkpoint\n",
    "    print(\"\\nLoading model from checkpoint...\")\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        CHECKPOINT_PATH,\n",
    "        num_labels=NUM_LABELS,\n",
    "        id2label=id2label,\n",
    "        label2id=label2id\n",
    "    )\n",
    "    \n",
    "    # Move model to GPU if available\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    \n",
    "    # Define a custom collate function for DataLoader\n",
    "    def collate_fn(batch):\n",
    "        \"\"\"Collate function for DataLoader\"\"\"\n",
    "        return {\n",
    "            'input_ids': torch.stack([torch.tensor(item['input_ids']) for item in batch]),\n",
    "            'attention_mask': torch.stack([torch.tensor(item['attention_mask']) for item in batch]),\n",
    "            'labels': torch.tensor([item['label'] for item in batch])\n",
    "        }\n",
    "\n",
    "    # Use DataLoader for batching\n",
    "    from torch.utils.data import DataLoader\n",
    "    test_dataloader = DataLoader(tokenized_test_data, batch_size=16, collate_fn=collate_fn)\n",
    "\n",
    "    # Run inference on the test dataset\n",
    "    print(\"\\nPerforming inference on the test dataset...\")\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "\n",
    "    for batch in test_dataloader:\n",
    "        # Move data to the appropriate device (GPU/CPU)\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        \n",
    "        logits = outputs.logits\n",
    "        preds = torch.argmax(logits, dim=-1).cpu().numpy()\n",
    "        \n",
    "        predictions.extend(preds)\n",
    "        true_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    # Compute accuracy manually\n",
    "    accuracy = accuracy_score(true_labels, predictions)\n",
    "    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d4e346-2f83-4b83-954f-bfb050fa77a2",
   "metadata": {},
   "source": [
    "# Load and inference using pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "af6c8198-c08b-4f1d-baf0-23f493e4d2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_classifier():\n",
    "    # Single example \n",
    "    from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification\n",
    "    import torch\n",
    "\n",
    "    # Define the model and checkpoint paths\n",
    "    MODEL_PATH = \"trec_model/checkpoint-682\"  # Adjust path to your model checkpoint\n",
    "\n",
    "    # Load the pipeline for multi-class classification (6 classes)\n",
    "    classifier = pipeline(\n",
    "        \"text-classification\",\n",
    "        model=MODEL_PATH,\n",
    "        tokenizer=MODEL_PATH,\n",
    "        device=0 if torch.cuda.is_available() else -1  # Use GPU if available\n",
    "    )\n",
    "    return classifier\n",
    "\n",
    "\n",
    "def load_model_and_tokenizer():\n",
    "    MODEL_PATH = \"trec_model/checkpoint-682\"  # Adjust path to your model checkpoint\n",
    "    # Optionally, if you want to use the model and tokenizer directly:\n",
    "    # 1. Load tokenizer and model\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(MODEL_PATH)\n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b1df6f00-f447-4cd2-a08d-8fb5131bb8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(TEXT, classifier):\n",
    "    # Classify the text\n",
    "    predictions = classifier(TEXT)\n",
    "\n",
    "    # Print the predictions\n",
    "    print(predictions)\n",
    "    \n",
    "def classify2(TEXT, model, tokenizer):\n",
    "    # 2. Prepare inputs\n",
    "    inputs = tokenizer(TEXT, return_tensors=\"pt\")\n",
    "\n",
    "    # 3. Run inference (with no gradient computation)\n",
    "    with torch.no_grad():\n",
    "        logits = model(**inputs).logits\n",
    "\n",
    "    # 4. Get the predicted class id and the label\n",
    "    predicted_class_id = logits.argmax().item()\n",
    "    predicted_class = model.config.id2label[predicted_class_id]\n",
    "    print(logits)\n",
    "    print(f\"Predicted class: {predicted_class} (ID: {predicted_class_id})\")\n",
    "    \n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def classify2(TEXT, model, tokenizer):\n",
    "    \"\"\"\n",
    "    Classify text and print detailed scores for all classes\n",
    "    \n",
    "    Args:\n",
    "        TEXT: Input text to classify\n",
    "        model: Trained model\n",
    "        tokenizer: Tokenizer\n",
    "    \"\"\"\n",
    "    # 1. Prepare inputs\n",
    "    inputs = tokenizer(TEXT, return_tensors=\"pt\")\n",
    "    \n",
    "    # Move to same device as model\n",
    "    device = next(model.parameters()).device\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    \n",
    "    # 2. Run inference (with no gradient computation)\n",
    "    with torch.no_grad():\n",
    "        logits = model(**inputs).logits\n",
    "    \n",
    "    # 3. Convert logits to probabilities using softmax\n",
    "    probabilities = F.softmax(logits, dim=-1)\n",
    "    \n",
    "    # 4. Get the predicted class id and the label\n",
    "    predicted_class_id = logits.argmax().item()\n",
    "    predicted_class = model.config.id2label[predicted_class_id]\n",
    "    confidence = probabilities[0][predicted_class_id].item()\n",
    "    \n",
    "    # 5. Print results\n",
    "    print(f\"\\nInput text: {TEXT}\")\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Predicted class: {predicted_class} (ID: {predicted_class_id})\")\n",
    "    print(f\"Confidence: {confidence:.4f} ({confidence*100:.2f}%)\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    print(f\"\\nRaw logits:\")\n",
    "    print(logits)\n",
    "    \n",
    "    print(f\"\\nScores for all classes:\")\n",
    "    print(f\"{'Class':<15} {'Label':<12} {'Probability':<12} {'Percentage'}\")\n",
    "    print(f\"{'-'*60}\")\n",
    "    \n",
    "    # Sort by probability (descending)\n",
    "    probs_list = probabilities[0].cpu().numpy()\n",
    "    sorted_indices = probs_list.argsort()[::-1]\n",
    "    \n",
    "    for idx in sorted_indices:\n",
    "        class_label = model.config.id2label[idx]\n",
    "        prob = probs_list[idx]\n",
    "        marker = \"★\" if idx == predicted_class_id else \" \"\n",
    "        print(f\"{marker} Class {idx:<7} {class_label:<12} {prob:<12.6f} {prob*100:>6.2f}%\")\n",
    "    \n",
    "    return {\n",
    "        'predicted_class': predicted_class,\n",
    "        'predicted_class_id': predicted_class_id,\n",
    "        'confidence': confidence,\n",
    "        'probabilities': probs_list,\n",
    "        'logits': logits[0].cpu().numpy()\n",
    "    }\n",
    "\n",
    "\n",
    "# Alternative: More compact version\n",
    "def classify2_compact(TEXT, model, tokenizer):\n",
    "    \"\"\"\n",
    "    Compact version with scores\n",
    "    \"\"\"\n",
    "    inputs = tokenizer(TEXT, return_tensors=\"pt\")\n",
    "    device = next(model.parameters()).device\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        logits = model(**inputs).logits\n",
    "    \n",
    "    probabilities = F.softmax(logits, dim=-1)[0]\n",
    "    predicted_class_id = logits.argmax().item()\n",
    "    \n",
    "    print(f\"\\nText: {TEXT}\")\n",
    "    print(f\"\\nPrediction: {model.config.id2label[predicted_class_id]} ({probabilities[predicted_class_id]:.2%})\")\n",
    "    print(f\"\\nAll scores:\")\n",
    "    for idx, prob in enumerate(probabilities):\n",
    "        label = model.config.id2label[idx]\n",
    "        print(f\"  {label:10s}: {prob:.4f} ({prob:.2%})\")\n",
    "\n",
    "\n",
    "# Alternative: With visualization\n",
    "def classify2_visual(TEXT, model, tokenizer):\n",
    "    \"\"\"\n",
    "    Version with visual bar chart\n",
    "    \"\"\"\n",
    "    import torch.nn.functional as F\n",
    "    \n",
    "    inputs = tokenizer(TEXT, return_tensors=\"pt\")\n",
    "    device = next(model.parameters()).device\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        logits = model(**inputs).logits\n",
    "    \n",
    "    probabilities = F.softmax(logits, dim=-1)[0]\n",
    "    predicted_class_id = logits.argmax().item()\n",
    "    \n",
    "    print(f\"\\nText: {TEXT}\")\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"Prediction: {model.config.id2label[predicted_class_id]}\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "    \n",
    "    # Sort by probability\n",
    "    probs_sorted = sorted(\n",
    "        enumerate(probabilities.cpu().numpy()),\n",
    "        key=lambda x: x[1],\n",
    "        reverse=True\n",
    "    )\n",
    "    \n",
    "    for idx, prob in probs_sorted:\n",
    "        label = model.config.id2label[idx]\n",
    "        bar_length = int(prob * 50)  # Scale to 50 chars max\n",
    "        bar = '█' * bar_length\n",
    "        marker = '→' if idx == predicted_class_id else ' '\n",
    "        print(f\"{marker} {label:10s} {prob:6.2%} |{bar}\")\n",
    "    \n",
    "    return probabilities.cpu().numpy()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "28cdf762-9dff-4fa3-8ede-9c509a8964db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'HUM', 'score': 0.9944992065429688}]\n"
     ]
    }
   ],
   "source": [
    "classifier = load_classifier()\n",
    "classify(\"Who is Newton\", classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e0a08693-f46f-4fc3-91e4-3dd0bba038e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'NUM', 'score': 0.9761038422584534}, {'label': 'NUM', 'score': 0.9943133592605591}]\n"
     ]
    }
   ],
   "source": [
    "classify([\"The number is 5\", \n",
    "          \"How many students in the class\"], classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c1c28545-cbcf-4dc9-a496-f8519cbac8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, tokenizer = load_model_and_tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "df6aa891-c098-4e36-9aad-1f5f7307cb45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Input text: The number is 5\n",
      "\n",
      "============================================================\n",
      "Predicted class: NUM (ID: 5)\n",
      "Confidence: 0.9761 (97.61%)\n",
      "============================================================\n",
      "\n",
      "Raw logits:\n",
      "tensor([[-1.2781, -1.2032, -0.8557, -0.9768, -1.0826,  4.2516]])\n",
      "\n",
      "Scores for all classes:\n",
      "Class           Label        Probability  Percentage\n",
      "------------------------------------------------------------\n",
      "★ Class 5       NUM          0.976104      97.61%\n",
      "  Class 2       ENTY         0.005908       0.59%\n",
      "  Class 3       HUM          0.005234       0.52%\n",
      "  Class 4       LOC          0.004709       0.47%\n",
      "  Class 1       DESC         0.004174       0.42%\n",
      "  Class 0       ABBR         0.003872       0.39%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'predicted_class': 'NUM',\n",
       " 'predicted_class_id': 5,\n",
       " 'confidence': 0.9761038422584534,\n",
       " 'probabilities': array([0.00387231, 0.00417374, 0.00590769, 0.00523388, 0.00470855,\n",
       "        0.97610384], dtype=float32),\n",
       " 'logits': array([-1.2781407 , -1.2031807 , -0.8557379 , -0.97684044, -1.0826124 ,\n",
       "         4.251576  ], dtype=float32)}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify2(\"The number is 5\", model, tokenizer)\n",
    "# classify2_compact(\"The number is 5\", model, tokenizer)\n",
    "# classify2_visual(\"The number is 5\", model, tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "60d6fc9e-2779-467b-a99b-e9869a47bde2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_test():\n",
    "    # Predict multi example\n",
    "    from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification\n",
    "    import json\n",
    "    from sklearn.metrics import accuracy_score\n",
    "\n",
    "    # Define the model checkpoint path\n",
    "    MODEL_PATH = \"trec_model/checkpoint-1364\"  # Update to your checkpoint path\n",
    "\n",
    "    # Load the pipeline for multi-class classification (6 classes)\n",
    "    print(\"\\nLoading model and tokenizer...\")\n",
    "    classifier = pipeline(\n",
    "        \"text-classification\",\n",
    "        model=MODEL_PATH,\n",
    "        tokenizer=MODEL_PATH,\n",
    "        device=0 if torch.cuda.is_available() else -1  # Use GPU if available\n",
    "    )\n",
    "    dataset = load_from_json('trec_test.json')\n",
    "\n",
    "    # Load texts and labels from trec_test.json\n",
    "    test_texts, true_labels = dataset[\"text\"], dataset[\"label\"]\n",
    "\n",
    "    # Perform predictions using the pipeline\n",
    "    print(\"\\nClassifying text data from trec_test.json...\")\n",
    "\n",
    "    # Classify the texts\n",
    "    predictions = classifier(test_texts)\n",
    "\n",
    "    # Extract predicted labels (the 'label' field from the predictions)\n",
    "    predicted_labels = [prediction['label'] for prediction in predictions]\n",
    "\n",
    "    # Print out the predictions and compute accuracy\n",
    "    correct_predictions = sum([1 for true, pred in zip(true_labels, predicted_labels) if true == label2id[pred]])\n",
    "    total_predictions = len(true_labels)\n",
    "    accuracy = correct_predictions / total_predictions\n",
    "\n",
    "    # Print the accuracy\n",
    "    print(f\"\\nAccuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "    # Optionally, if you want\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e8fdbe1f-f437-4a7b-8768-91403221c67b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading model and tokenizer...\n",
      "\n",
      "Classifying text data from trec_test.json...\n",
      "\n",
      "Accuracy: 97.00%\n"
     ]
    }
   ],
   "source": [
    "evaluate_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d449d65-47ad-49ca-84b7-16b963be3e0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quocvh",
   "language": "python",
   "name": "quocvh"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
